{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if device supports CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For reference:\n",
    "\n",
    "tensor image structure = (Batch(size), Channels(count), Height, Width)\n",
    "\n",
    "Image information:\n",
    "\n",
    "dimension: 300 x 300\n",
    "bit depth: 24 bit (rgb : 3 x 8 bits)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_img_mean_std(loader) -> float:\n",
    "    \"\"\"\n",
    "    Generates an approximation of the mean and std deviation for a given dataset of images.\n",
    "    Approximations are much, much faster to calculate than exact values and shouldn't be too far off.\n",
    "\n",
    "    :param loader: dataset to have calculated\n",
    "    :return: mean, std deviation\n",
    "    \"\"\"\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_image_count = 0\n",
    "\n",
    "    for imgs, _ in loader:\n",
    "        batch_img_count = imgs.size(0)\n",
    "        imgs = imgs.view(batch_img_count, imgs.size(1), -1)\n",
    "        mean += imgs.mean(2).sum(0)\n",
    "        std += imgs.std(2).sum(0)\n",
    "        total_image_count += batch_img_count\n",
    "\n",
    "    mean /= total_image_count\n",
    "    std /= total_image_count\n",
    "\n",
    "    return mean, std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define transformation\n",
    "initial_train_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "desired_batch_size = 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import dataset\n",
    "original_train_dataset = datasets.ImageFolder(\"traindata\", transform=initial_train_transform)\n",
    "\n",
    "# create loader for generating mean/std deviation\n",
    "full_train_loader = torch.utils.data.DataLoader(original_train_dataset, batch_size=desired_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# show what classes have been identified\n",
    "classes = original_train_dataset.classes\n",
    "print(\"Classes:\", classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_mean, train_std = get_img_mean_std(full_train_loader)\n",
    "# print(\"mean: \" + str(train_mean) + \", std: \" + str(train_std))\n",
    "# output: mean: tensor([0.5474, 0.4110, 0.3391]), std: tensor([0.2301, 0.2384, 0.2308])\n",
    "\n",
    "# already calculated once so no need to do every time\n",
    "train_mean = torch.tensor([0.5474, 0.4110, 0.3391])\n",
    "train_std = torch.tensor([0.2301, 0.2384, 0.2308])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(size=(150, 150), scale=(0.4, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])\n",
    "\n",
    "# used for validation dataset as well\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set new transform\n",
    "train_dataset = datasets.ImageFolder(\"traindata\", transform=train_transform)\n",
    "\n",
    "# create validation set for better training (and because I don't have the test set)\n",
    "train_size = 3600\n",
    "val_size = 900\n",
    "# 3600, 900 <- 80/20 split\n",
    "\n",
    "train_set, val_set = random_split(original_train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(7))\n",
    "\n",
    "\n",
    "# create loaders for train and val sets\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=desired_batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=desired_batch_size, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    plt.grid(visible=None)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(utils.make_grid(images))\n",
    "\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(desired_batch_size)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First I need to try a simple MLP model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# useful for if I want to disable MLP section when repeatedly re-running for CNN\n",
    "enable_mlp_section = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    # define our MLP\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(in_features=270000, out_features=1000)\n",
    "            self.fc2 = nn.Linear(in_features=1000, out_features=1000)\n",
    "            self.fc3 = nn.Linear(in_features=1000, out_features=800)\n",
    "            self.fc4 = nn.Linear(in_features=800, out_features=800)\n",
    "            self.fc5 = nn.Linear(in_features=800, out_features=3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = F.relu(self.fc4(x))\n",
    "            x = self.fc5(x)\n",
    "            return x\n",
    "\n",
    "    mlp_model = MLP()\n",
    "    mlp_model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(mlp_model.parameters(), lr=0.001, momentum=0.8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    # iterate over the dataset\n",
    "    best_val_acc = 0.0\n",
    "    epoch_used = 0\n",
    "    train_time = 0\n",
    "\n",
    "    # stop after this many epochs with no validation improvement\n",
    "    early_stop_count = 8\n",
    "    epochs_with_no_improv = 0\n",
    "\n",
    "    mlp_train_history = pd.DataFrame(columns=[\"train_loss\", \"train_accuracy\", \"val_loss\", \"val_accuracy\"])\n",
    "\n",
    "    for epoch in range(100):\n",
    "        # train the model\n",
    "        mlp_model.train()\n",
    "\n",
    "        train_accuracy = 0.0\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = mlp_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "        train_accuracy = train_accuracy / total\n",
    "        train_loss = train_loss / total\n",
    "\n",
    "        # evaluate the model\n",
    "        mlp_model.eval()\n",
    "\n",
    "        val_accuracy = 0.0\n",
    "        val_loss = 0.0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = mlp_model(inputs)\n",
    "            # Find the Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Calculate Loss\n",
    "            val_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            val_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "        val_accuracy = val_accuracy / total\n",
    "        val_loss = val_loss / total\n",
    "\n",
    "        print(\"Epoch: \" + str(epoch+1) + \"\\n\" +\n",
    "              \"Train loss: \" + str(train_loss) + \", Train accuracy: \" + str(train_accuracy) + \"\\n\" +\n",
    "              \"Val loss: \" + str(val_loss) + \", Val Accuracy: \" + str(val_accuracy) + \"\\n\")\n",
    "\n",
    "        mlp_train_history.loc[len(mlp_train_history)] = [train_loss, train_accuracy, val_loss, val_accuracy]\n",
    "\n",
    "        if val_accuracy > best_val_acc:\n",
    "            print(\"Validation accuracy improved: \" + str(best_val_acc) + \" --> \" + str(val_accuracy))\n",
    "            print(\"Saving model \\n\")\n",
    "            epoch_used = epoch\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(mlp_model.state_dict(), \"mlp_model.pth\")\n",
    "            epochs_with_no_improv = 0\n",
    "        else:\n",
    "            epochs_with_no_improv += 1\n",
    "            print(epochs_with_no_improv)\n",
    "\n",
    "        if epochs_with_no_improv >= early_stop_count:\n",
    "            print(\"Stopping early, no validation improvement in \" + str(early_stop_count) + \" epochs \\n\")\n",
    "            break\n",
    "\n",
    "    print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    x = range(len(mlp_train_history))\n",
    "\n",
    "    # plot params\n",
    "    plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    plt.grid(visible=None)\n",
    "\n",
    "    plt.plot(x, mlp_train_history[\"train_loss\"].to_numpy(), label=\"Train\")\n",
    "    plt.plot(x, mlp_train_history[\"val_loss\"].to_numpy(), label=\"Validation\")\n",
    "    plt.axvline(x=epoch_used, label=\"Selected point\", color=\"g\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"MLP Loss\", fontsize=18)\n",
    "    plt.xlabel(\"Epochs\", fontsize=14)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(\"mlp_loss.png\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    x = range(len(mlp_train_history))\n",
    "\n",
    "    # plot params\n",
    "    plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    plt.grid(visible=None)\n",
    "\n",
    "    plt.plot(x, mlp_train_history[\"train_accuracy\"].to_numpy(), label=\"Train\")\n",
    "    plt.plot(x, mlp_train_history[\"val_accuracy\"].to_numpy(), label=\"Validation\")\n",
    "    plt.axvline(x=epoch_used, label=\"Selected point\", color=\"g\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"MLP Accuracy\", fontsize=18)\n",
    "    plt.xlabel(\"Epochs\", fontsize=14)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(\"mlp_accuracy.png\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    # load the model from file\n",
    "    mlp_model = MLP()\n",
    "    mlp_model.load_state_dict(torch.load(\"mlp_model.pth\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    outputs = mlp_model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(desired_batch_size)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = mlp_model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 900 validation images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy of the network on the 900 validation images: 54 %"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # for confusion matrix\n",
    "    results = pd.DataFrame(columns=[\"true\", \"pred\"])\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            outputs = mlp_model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                results.loc[len(results)] = [str(label), str(prediction)]\n",
    "\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy for class: cherry is 47.1 %\n",
    "Accuracy for class: strawberry is 54.2 %\n",
    "Accuracy for class: tomato is 62.4 %"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_confusion_matrix(true, pred, title):\n",
    "    cf_matrix = confusion_matrix(true, pred)\n",
    "\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 10, index = [i for i in classes], columns = [i for i in classes])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(df_cm, ax=ax, annot=True)\n",
    "    fig.set_size_inches(12, 8)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Ground truth\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "#plt.savefig('output.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#results.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if enable_mlp_section:\n",
    "    show_confusion_matrix(results.true, results.pred, \"MLP cherry Confusion Matrix\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# takes 'inspiration' from vgg architecture\n",
    "\n",
    "# define our CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=20736, out_features=4096),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(in_features=4096, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_save_path = \"model.pth\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterate over the dataset\n",
    "best_val_acc = 0.0\n",
    "epoch_used = 0\n",
    "training_start_time = datetime.now()  # millis\n",
    "\n",
    "# stop after this many epochs with no validation improvement\n",
    "early_stop_count = 25\n",
    "epochs_with_no_improv = 0\n",
    "\n",
    "cnn_train_history = pd.DataFrame(columns=[\"train_loss\", \"train_accuracy\", \"val_loss\", \"val_accuracy\"])\n",
    "\n",
    "for epoch in range(200):\n",
    "    # train the model\n",
    "    cnn_model.train()\n",
    "\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    train_accuracy = train_accuracy / total\n",
    "    train_loss = train_loss / total\n",
    "\n",
    "    # evaluate the model\n",
    "    cnn_model.eval()\n",
    "\n",
    "    val_accuracy = 0.0\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = cnn_model(inputs)\n",
    "        # Find the Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Calculate Loss\n",
    "        val_loss += loss.item()\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        val_accuracy += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    val_accuracy = val_accuracy / total\n",
    "    val_loss = val_loss / total\n",
    "\n",
    "    print(\"Epoch: \" + str(epoch+1) + \"\\n\" +\n",
    "          \"Train loss: \" + str(train_loss) + \", Train accuracy: \" + str(train_accuracy) + \"\\n\" +\n",
    "          \"Val loss: \" + str(val_loss) + \", Val Accuracy: \" + str(val_accuracy) + \"\\n\")\n",
    "\n",
    "    cnn_train_history.loc[len(cnn_train_history)] = [train_loss, train_accuracy, val_loss, val_accuracy]\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        print(\"Validation accuracy improved: \" + str(best_val_acc) + \" --> \" + str(val_accuracy))\n",
    "        print(\"Saving model \\n\")\n",
    "        epoch_used = epoch\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(cnn_model.state_dict(), model_save_path)\n",
    "        epochs_with_no_improv = 0\n",
    "    else:\n",
    "        epochs_with_no_improv += 1\n",
    "\n",
    "    if epochs_with_no_improv >= early_stop_count:\n",
    "        print(\"Stopping early, no validation improvement in \" + str(early_stop_count) + \" epochs \\n\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_time = (time.time() * 1000) - training_start_time\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(\"Took \" + train_time + \"minutes\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = range(len(cnn_train_history))\n",
    "\n",
    "# plot params\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.grid(visible=None)\n",
    "\n",
    "plt.plot(x, cnn_train_history[\"train_loss\"].to_numpy(), label=\"Train\")\n",
    "plt.plot(x, cnn_train_history[\"val_loss\"].to_numpy(), label=\"Validation\")\n",
    "plt.axvline(x=epoch_used, label=\"Selected point\", color=\"g\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"CNN Loss\", fontsize=18)\n",
    "plt.xlabel(\"Epochs\", fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"cnn_loss.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = range(len(cnn_train_history))\n",
    "\n",
    "# plot params\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.grid(visible=None)\n",
    "\n",
    "plt.plot(x, cnn_train_history[\"train_accuracy\"].to_numpy(), label=\"Train\")\n",
    "plt.plot(x, cnn_train_history[\"val_accuracy\"].to_numpy(), label=\"Validation\")\n",
    "plt.axvline(x=epoch_used, label=\"Selected point\", color=\"g\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"CNN Accuracy\", fontsize=18)\n",
    "plt.xlabel(\"Epochs\", fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"cnn_accuracy.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(desired_batch_size)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the model from file\n",
    "cnn_model = CNN()\n",
    "cnn_model.load_state_dict(torch.load(model_save_path))\n",
    "cnn_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outputs = cnn_model(images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(desired_batch_size)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cnn_model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 900 validation images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "output: Accuracy of the network on the 900 validation images: 83 %"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "results = pd.DataFrame(columns=[\"true\", \"pred\"])\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn_model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            results.loc[len(results)] = [str(label), str(prediction)]\n",
    "\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "output:\n",
    "Accuracy for class: cherry is 84.0 %\n",
    "Accuracy for class: strawberry is 89.2 %\n",
    "Accuracy for class: tomato is 78.4 %"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
